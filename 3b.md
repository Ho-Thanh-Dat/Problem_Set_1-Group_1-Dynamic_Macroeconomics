    import numpy as np

    def simulate_markov_chain(T, z, pi, p):
    """
    Simulates a Markov Chain given:
    T  - Number of time steps
    z  - State values
    pi - Initial probability distribution
    p  - Transition probability matrix
    """
    assert T >= 2, "T must be at least 2"

    np.random.seed(42)  # Set a seed for reproducibility

    P = np.cumsum(p)  # CDF of Initial Distribution
    Π = np.cumsum(pi, axis=1)  # CDF of Transition Matrix

    # Step 1: Initialize the first state
    u1 = np.random.uniform(0, 1)
    k = np.searchsorted(P, u1)  # Find the first state index
    y = [z[k]]  # Store the states

    # Step 2: Simulate the Markov Chain for T time steps
    for t in range(1, T):
        ut = np.random.uniform(0, 1)
        j = k  # Current state
        k = np.searchsorted(Π[j], ut)  # Determine next state
        y.append(z[k])

    return y
